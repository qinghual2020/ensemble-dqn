Collecting experience...
Ep:  0 | Ep_r:  34.0 | Steps:  33 | Ep_Loss: 0.0000
Ep:  5 | Ep_r:  51.0 | Steps:  50 | Ep_Loss: 0.0000
Ep:  10 | Ep_r:  26.0 | Steps:  25 | Ep_Loss: 0.0000
Ep:  15 | Ep_r:  25.0 | Steps:  24 | Ep_Loss: 0.0000
Ep:  20 | Ep_r:  17.0 | Steps:  16 | Ep_Loss: 0.0000
Ep:  25 | Ep_r:  10.0 | Steps:  9 | Ep_Loss: 0.0000
Ep:  30 | Ep_r:  17.0 | Steps:  16 | Ep_Loss: 0.0000
Ep:  35 | Ep_r:  18.0 | Steps:  17 | Ep_Loss: 0.0000
Ep:  40 | Ep_r:  15.0 | Steps:  14 | Ep_Loss: 0.0000
Ep:  45 | Ep_r:  30.0 | Steps:  29 | Ep_Loss: 0.0000
Ep:  50 | Ep_r:  20.0 | Steps:  19 | Ep_Loss: 0.0000
Ep:  55 | Ep_r:  23.0 | Steps:  22 | Ep_Loss: 0.0000
Ep:  60 | Ep_r:  33.0 | Steps:  32 | Ep_Loss: 0.0000
Ep:  65 | Ep_r:  53.0 | Steps:  52 | Ep_Loss: 0.0000
Ep:  70 | Ep_r:  20.0 | Steps:  19 | Ep_Loss: 0.0000
Ep:  75 | Ep_r:  18.0 | Steps:  17 | Ep_Loss: 0.3155
Ep:  80 | Ep_r:  13.0 | Steps:  12 | Ep_Loss: 0.2104
Ep:  85 | Ep_r:  16.0 | Steps:  15 | Ep_Loss: 0.2551
Ep:  90 | Ep_r:  53.0 | Steps:  52 | Ep_Loss: 0.6537
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
Ep:  95 | Ep_r:  33.0 | Steps:  32 | Ep_Loss: 0.3991
Ep:  100 | Ep_r:  20.0 | Steps:  19 | Ep_Loss: 0.2595
Ep:  105 | Ep_r:  20.0 | Steps:  19 | Ep_Loss: 0.2556
Ep:  110 | Ep_r:  38.0 | Steps:  37 | Ep_Loss: 0.5045
Ep:  115 | Ep_r:  21.0 | Steps:  20 | Ep_Loss: 0.2333
Ep:  120 | Ep_r:  13.0 | Steps:  12 | Ep_Loss: 0.1330
Ep:  125 | Ep_r:  30.0 | Steps:  29 | Ep_Loss: 0.3734
Ep:  130 | Ep_r:  21.0 | Steps:  20 | Ep_Loss: 0.2731
Ep:  135 | Ep_r:  30.0 | Steps:  29 | Ep_Loss: 0.3146
Ep:  140 | Ep_r:  39.0 | Steps:  38 | Ep_Loss: 0.4982
Ep:  145 | Ep_r:  71.0 | Steps:  70 | Ep_Loss: 0.7548
Ep:  150 | Ep_r:  65.0 | Steps:  64 | Ep_Loss: 0.7829
Ep:  155 | Ep_r:  25.0 | Steps:  24 | Ep_Loss: 0.2390
Ep:  160 | Ep_r:  24.0 | Steps:  23 | Ep_Loss: 0.2567
Ep:  165 | Ep_r:  14.0 | Steps:  13 | Ep_Loss: 0.1573
Ep:  170 | Ep_r:  32.0 | Steps:  31 | Ep_Loss: 0.5352
Ep:  175 | Ep_r:  56.0 | Steps:  55 | Ep_Loss: 0.7626
Ep:  180 | Ep_r:  19.0 | Steps:  18 | Ep_Loss: 0.2564
Ep:  185 | Ep_r:  21.0 | Steps:  20 | Ep_Loss: 0.2624
Ep:  190 | Ep_r:  17.0 | Steps:  16 | Ep_Loss: 0.1744
Ep:  195 | Ep_r:  58.0 | Steps:  57 | Ep_Loss: 0.7450
Ep:  200 | Ep_r:  31.0 | Steps:  30 | Ep_Loss: 0.3852
Ep:  205 | Ep_r:  264.0 | Steps:  263 | Ep_Loss: 2.7875
Ep:  210 | Ep_r:  94.0 | Steps:  93 | Ep_Loss: 0.8496
Ep:  215 | Ep_r:  16.0 | Steps:  15 | Ep_Loss: 0.2018
Ep:  220 | Ep_r:  31.0 | Steps:  30 | Ep_Loss: 0.2741
Ep:  225 | Ep_r:  30.0 | Steps:  29 | Ep_Loss: 0.2679
Ep:  230 | Ep_r:  97.0 | Steps:  96 | Ep_Loss: 1.0258
Ep:  235 | Ep_r:  80.0 | Steps:  79 | Ep_Loss: 0.7391
Ep:  240 | Ep_r:  102.0 | Steps:  101 | Ep_Loss: 1.0715
Ep:  245 | Ep_r:  88.0 | Steps:  87 | Ep_Loss: 1.1668
Ep:  250 | Ep_r:  81.0 | Steps:  80 | Ep_Loss: 1.2047
Ep:  255 | Ep_r:  74.0 | Steps:  73 | Ep_Loss: 1.0353
Ep:  260 | Ep_r:  149.0 | Steps:  148 | Ep_Loss: 2.0609
Ep:  265 | Ep_r:  90.0 | Steps:  89 | Ep_Loss: 1.3205
Ep:  270 | Ep_r:  53.0 | Steps:  52 | Ep_Loss: 0.7616
Ep:  275 | Ep_r:  470.0 | Steps:  469 | Ep_Loss: 7.4600
Ep:  280 | Ep_r:  101.0 | Steps:  100 | Ep_Loss: 1.5575
Ep:  285 | Ep_r:  71.0 | Steps:  70 | Ep_Loss: 1.1398
Ep:  290 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 6.9496
Ep:  295 | Ep_r:  207.0 | Steps:  206 | Ep_Loss: 3.7788
Ep:  300 | Ep_r:  84.0 | Steps:  83 | Ep_Loss: 1.0808
Ep:  305 | Ep_r:  439.0 | Steps:  438 | Ep_Loss: 4.6052
Ep:  310 | Ep_r:  65.0 | Steps:  64 | Ep_Loss: 0.7598
Ep:  315 | Ep_r:  53.0 | Steps:  52 | Ep_Loss: 0.7449
Ep:  320 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 4.5011
Ep:  325 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 7.0025
Ep:  330 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 4.5794
Ep:  335 | Ep_r:  290.0 | Steps:  289 | Ep_Loss: 2.7929
Ep:  340 | Ep_r:  126.0 | Steps:  125 | Ep_Loss: 1.5418
Ep:  345 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 5.6542
Ep:  350 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 4.8550
Ep:  355 | Ep_r:  366.0 | Steps:  365 | Ep_Loss: 4.6244
Ep:  360 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 4.4916
Ep:  365 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 5.0796
Ep:  370 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 4.9022
Ep:  375 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 3.9126
Ep:  380 | Ep_r:  147.0 | Steps:  146 | Ep_Loss: 1.7243
Ep:  385 | Ep_r:  48.0 | Steps:  47 | Ep_Loss: 0.5437
Ep:  390 | Ep_r:  43.0 | Steps:  42 | Ep_Loss: 0.6033
Ep:  395 | Ep_r:  54.0 | Steps:  53 | Ep_Loss: 0.4949
Ep:  400 | Ep_r:  90.0 | Steps:  89 | Ep_Loss: 0.8595
Ep:  405 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 4.2938
Ep:  410 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 5.7843
Ep:  415 | Ep_r:  79.0 | Steps:  78 | Ep_Loss: 1.0427
Ep:  420 | Ep_r:  75.0 | Steps:  74 | Ep_Loss: 0.9024
Ep:  425 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 3.9309
Ep:  430 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 4.2767
Ep:  435 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 3.8019
Ep:  440 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 5.1435
Ep:  445 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 5.2730
Ep:  450 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 4.4434
Ep:  455 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 5.0787
Ep:  460 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 4.0816
Ep:  465 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 4.5157
Ep:  470 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 4.6292
Ep:  475 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 5.6162
Ep:  480 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 5.2865
Ep:  485 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 4.7288
Ep:  490 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 4.8572
Ep:  495 | Ep_r:  500.0 | Steps:  499 | Ep_Loss: 4.3210